{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serious-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "from matplotlib import colors as c\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "concrete-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:50% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:50% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "essential-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init(traj_label, past_traj_data, future_traj_data, traj_weights):\n",
    "    assert len(future_traj_data)==len(traj_label)\n",
    "    \n",
    "    # skip the first t0 data\n",
    "    past_data = past_traj_data\n",
    "    future_data = future_traj_data\n",
    "    label = traj_label\n",
    "    \n",
    "    # data shape\n",
    "    data_shape = past_data.shape[1:]\n",
    "    \n",
    "    n_data = len(past_data)\n",
    "    \n",
    "    # 90% random test/train split\n",
    "    p = np.random.permutation(n_data)\n",
    "    past_data = past_data[p]\n",
    "    future_data = future_data[p]\n",
    "    label = label[p]\n",
    "    \n",
    "    past_data_train = past_data[0: (9 * n_data) // 10]\n",
    "    past_data_test = past_data[(9 * n_data) // 10:]\n",
    "    \n",
    "    future_data_train = future_data[0: (9 * n_data) // 10]\n",
    "    future_data_test = future_data[(9 * n_data) // 10:]\n",
    "    \n",
    "    label_train = label[0: (9 * n_data) // 10]\n",
    "    label_test = label[(9 * n_data) // 10:]\n",
    "    \n",
    "    if traj_weights != None:\n",
    "        assert len(traj_data)==len(traj_weights)\n",
    "        weights = traj_weights[t0:(len(traj_data)-dt)]\n",
    "        weights = weights[p]\n",
    "        weights_train = weights[0: (9 * n_data) // 10]\n",
    "        weights_test = weights[(9 * n_data) // 10:]\n",
    "    else:\n",
    "        weights_train = None\n",
    "        weights_test = None\n",
    "    \n",
    "    return data_shape, past_data_train, future_data_train, label_train, weights_train,\\\n",
    "        past_data_test, future_data_test, label_test, weights_test\n",
    "\n",
    "# Loss function\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calculate_loss(IB, data_inputs, data_targets, data_weights, beta=1.0):\n",
    "    \n",
    "    # pass through VAE\n",
    "    outputs, z_sample, z_mean, z_logvar = IB.forward(data_inputs)\n",
    "    \n",
    "    # KL Divergence\n",
    "    log_p = IB.log_p(z_sample)\n",
    "    log_q = -0.5 * torch.sum(z_logvar + torch.pow(z_sample-z_mean, 2)\n",
    "                             /torch.exp(z_logvar), dim=1)\n",
    "    \n",
    "    if data_weights == None:\n",
    "        # Reconstruction loss is cross-entropy\n",
    "        reconstruction_error = torch.mean(torch.sum(-data_targets*outputs, dim=1))\n",
    "        \n",
    "        # KL Divergence\n",
    "        kl_loss = torch.mean(log_q-log_p)\n",
    "        \n",
    "    else:\n",
    "        # Reconstruction loss is cross-entropy\n",
    "        # reweighed\n",
    "        reconstruction_error = torch.mean(data_weights*torch.sum(-data_targets*outputs, dim=1))\n",
    "        \n",
    "        # KL Divergence\n",
    "        kl_loss = torch.mean(data_weights*(log_q-log_p))\n",
    "        \n",
    "    \n",
    "    loss = reconstruction_error + beta*kl_loss\n",
    "\n",
    "    return loss, reconstruction_error.float(), kl_loss.float()\n",
    "\n",
    "\n",
    "# Train and test model\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def sample_minibatch(past_data, data_labels, data_weights, indices, device):\n",
    "    sample_past_data = past_data[indices].to(device)\n",
    "    sample_data_labels = data_labels[indices].to(device)\n",
    "    \n",
    "    if data_weights == None:\n",
    "        sample_data_weights = None\n",
    "    else:\n",
    "        sample_data_weights = data_weights[indices].to(device)\n",
    "    \n",
    "    \n",
    "    return sample_past_data, sample_data_labels, sample_data_weights\n",
    "\n",
    "\n",
    "def train(IB, beta, train_past_data, train_future_data, init_train_data_labels, train_data_weights, \\\n",
    "          test_past_data, test_future_data, init_test_data_labels, test_data_weights, \\\n",
    "              learning_rate, lr_scheduler_step_size, lr_scheduler_gamma, batch_size, threshold, patience, refinements, log_interval, device, index):\n",
    "    IB.train()\n",
    "    \n",
    "    step = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    train_data_labels = init_train_data_labels\n",
    "    test_data_labels = init_test_data_labels\n",
    "\n",
    "    update_times = 0\n",
    "    unchanged_epochs = 0\n",
    "    epoch = 0\n",
    "\n",
    "    # initial state population\n",
    "    state_population0 = torch.sum(train_data_labels,dim=0).float()/train_data_labels.shape[0]\n",
    "\n",
    "    # generate the optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(IB.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_scheduler_step_size, gamma=lr_scheduler_gamma)\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        train_permutation = torch.randperm(len(train_past_data))\n",
    "        test_permutation = torch.randperm(len(test_past_data))\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(train_past_data), batch_size):\n",
    "            step += 1\n",
    "            \n",
    "            if i+batch_size>len(train_past_data):\n",
    "                break\n",
    "            \n",
    "            train_indices = train_permutation[i:i+batch_size]\n",
    "            \n",
    "            batch_inputs, batch_outputs, batch_weights = sample_minibatch(train_past_data, train_data_labels, \\\n",
    "                                                                       train_data_weights, train_indices, device)\n",
    "                    \n",
    "            loss, reconstruction_error, kl_loss= calculate_loss(IB, batch_inputs, \\\n",
    "                                                                batch_outputs, batch_weights, beta)\n",
    "            \n",
    "            # Stop if NaN is obtained\n",
    "            if(torch.isnan(loss).any()):\n",
    "                return True\n",
    "            \n",
    "            outputs, z_sample, z_mean, z_logvar = IB.forward(batch_inputs)\n",
    "            spa_loss = z_mean.pow(2).sum().div( z_mean.size(0) )\n",
    "            spa_loss_sig = 1/ (1+torch.exp(-(spa_loss-10)))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            spa_loss_sig.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    batch_inputs, batch_outputs, batch_weights = sample_minibatch(train_past_data, train_data_labels, \\\n",
    "                                                                               train_data_weights, train_indices, device)\n",
    "                            \n",
    "                    loss, reconstruction_error, kl_loss= calculate_loss(IB, batch_inputs, \\\n",
    "                                                                        batch_outputs, batch_weights, beta)\n",
    "                    train_time = time.time() - start\n",
    "                    \n",
    "                    outputs, z_sample, z_mean, z_logvar = IB.forward(batch_inputs)\n",
    "                    spa_loss = z_mean.pow(2).sum().div( z_mean.size(0) )\n",
    "                    spa_loss_sig = 1/ (1+torch.exp(-(spa_loss-10)))\n",
    "\n",
    "                    print(\"Iteration %i:\\tTime %f s\\nLoss (train) %f\\tKL loss (train): %f\\n\"\n",
    "                        \"Reconstruction loss (train) %f\\t Spatial loss %f\" % (\n",
    "                            step, train_time, loss, kl_loss, reconstruction_error,spa_loss_sig))\n",
    "                    \n",
    "                    j=i%len(test_permutation)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    test_indices = test_permutation[j:j+batch_size]\n",
    "                    \n",
    "                    batch_inputs, batch_outputs, batch_weights = sample_minibatch(test_past_data, test_data_labels, \\\n",
    "                                                                               test_data_weights, test_indices, device)\n",
    "                    \n",
    "                    loss, reconstruction_error, kl_loss = calculate_loss(IB, batch_inputs, \\\n",
    "                                                                         batch_outputs, batch_weights, beta)\n",
    "\n",
    "                    train_time = time.time() - start\n",
    "                    print(\"Loss (test) %f\\tKL loss (test): %f\\n\"\n",
    "                       \"Reconstruction loss (test) %f\" % (\n",
    "                           loss, kl_loss, reconstruction_error))\n",
    "                    \n",
    "\n",
    "        epoch+=1\n",
    "        \n",
    "        # check convergence\n",
    "        new_train_data_labels = IB.update_labels(train_future_data, batch_size)\n",
    "\n",
    "        # save the state population\n",
    "        state_population = torch.sum(new_train_data_labels,dim=0).float()/new_train_data_labels.shape[0]\n",
    "\n",
    "        print(state_population)\n",
    "\n",
    "        # print the state population change\n",
    "        state_population_change = torch.sqrt(torch.square(state_population-state_population0).sum())\n",
    "        \n",
    "        print('State population change=%f'%state_population_change)\n",
    "\n",
    "        # update state_population\n",
    "        state_population0 = state_population\n",
    "\n",
    "        scheduler.step()\n",
    "        if scheduler.gamma < 1:\n",
    "            print(\"Update lr to %f\"%(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        # check whether the change of the state population is smaller than the threshold\n",
    "        if state_population_change < threshold:\n",
    "            unchanged_epochs += 1\n",
    "            \n",
    "            if unchanged_epochs > patience:\n",
    "\n",
    "                # check whether only one state is found\n",
    "                if torch.sum(state_population>0)<2:\n",
    "                    print(\"Only one metastable state is found!\")\n",
    "                    break\n",
    "\n",
    "                # Stop only if update_times >= refinements\n",
    "                if IB.UpdateLabel and update_times < refinements:\n",
    "                    \n",
    "                    train_data_labels = new_train_data_labels\n",
    "                    test_data_labels = IB.update_labels(test_future_data, batch_size)\n",
    "    \n",
    "                    update_times+=1\n",
    "                    print(\"Update %d\\n\"%(update_times))\n",
    "                    \n",
    "                    # reset epoch and unchanged_epochs\n",
    "                    epoch = 0\n",
    "                    unchanged_epochs = 0\n",
    "\n",
    "                    # reset the representative-inputs\n",
    "                    representative_inputs = IB.estimatate_representative_inputs(train_past_data, train_data_weights, batch_size)\n",
    "                    IB.reset_representative(representative_inputs.to(device))\n",
    "    \n",
    "                    # reset the optimizer and scheduler\n",
    "                    optimizer = torch.optim.Adam(IB.parameters(), lr=learning_rate)\n",
    "\n",
    "                    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_scheduler_step_size, gamma=lr_scheduler_gamma)\n",
    "                    \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            unchanged_epochs = 0\n",
    "\n",
    "        print(\"Epoch: %d\\n\"%(epoch))\n",
    "\n",
    "    # output the saving path\n",
    "    total_training_time = time.time() - start\n",
    "    print(\"Total training time: %f\" % total_training_time)\n",
    "\n",
    "    return False\n",
    "\n",
    "def output_final_result(IB, device, train_past_data, train_future_data, train_data_labels, train_data_weights, \\\n",
    "                        test_past_data, test_future_data, test_data_labels, test_data_weights, batch_size, \\\n",
    "                             dt, beta, learning_rate, index=0):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # label update\n",
    "        if IB.UpdateLabel:\n",
    "            train_data_labels = IB.update_labels(train_future_data, batch_size)\n",
    "            test_data_labels = IB.update_labels(test_future_data, batch_size)\n",
    "        \n",
    "        final_result = []\n",
    "        # output the result\n",
    "        \n",
    "        loss, reconstruction_error, kl_loss= [0 for i in range(3)]\n",
    "        \n",
    "        for i in range(0, len(train_past_data), batch_size):\n",
    "            batch_inputs, batch_outputs, batch_weights = sample_minibatch(train_past_data, train_data_labels, train_data_weights, \\\n",
    "                                                                       range(i,min(i+batch_size,len(train_past_data))), IB.device)\n",
    "            loss1, reconstruction_error1, kl_loss1 = calculate_loss(IB, batch_inputs, batch_outputs, \\\n",
    "                                                                    batch_weights, beta)\n",
    "            loss += loss1*len(batch_inputs)\n",
    "            reconstruction_error += reconstruction_error1*len(batch_inputs)\n",
    "            kl_loss += kl_loss1*len(batch_inputs)\n",
    "            \n",
    "        \n",
    "        # output the result\n",
    "        loss/=len(train_past_data)\n",
    "        reconstruction_error/=len(train_past_data)\n",
    "        kl_loss/=len(train_past_data)\n",
    "                \n",
    "        final_result += [loss.data.cpu().numpy(), reconstruction_error.cpu().data.numpy(), kl_loss.cpu().data.numpy()]\n",
    "        print(\"Final: %d\\nLoss (train) %f\\tKL loss (train): %f\\n\"\n",
    "                    \"Reconstruction loss (train) %f\" % (index, loss, kl_loss, reconstruction_error))\n",
    "       \n",
    "    \n",
    "        loss, reconstruction_error, kl_loss = [0 for i in range(3)]\n",
    "        \n",
    "        for i in range(0, len(test_past_data), batch_size):\n",
    "            batch_inputs, batch_outputs, batch_weights = sample_minibatch(test_past_data, test_data_labels, test_data_weights, \\\n",
    "                                                                                         range(i,min(i+batch_size,len(test_past_data))), IB.device)\n",
    "            loss1, reconstruction_error1, kl_loss1 = calculate_loss(IB, batch_inputs, batch_outputs, \\\n",
    "                                                                   batch_weights, beta)\n",
    "            loss += loss1*len(batch_inputs)\n",
    "            reconstruction_error += reconstruction_error1*len(batch_inputs)\n",
    "            kl_loss += kl_loss1*len(batch_inputs)\n",
    "            \n",
    "        \n",
    "        # output the result\n",
    "        loss/=len(test_past_data)\n",
    "        reconstruction_error/=len(test_past_data)\n",
    "        kl_loss/=len(test_past_data)\n",
    "        \n",
    "        final_result += [loss.cpu().data.numpy(), reconstruction_error.cpu().data.numpy(), kl_loss.cpu().data.numpy()]\n",
    "        print(\"Loss (test) %f\\tKL loss (train): %f\\n\"\n",
    "            \"Reconstruction loss (test) %f\"% (loss, kl_loss, reconstruction_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "double-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPIB(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_type, z_dim, output_dim, data_shape, device, UpdateLabel= False, neuron_num1=128, \n",
    "                 neuron_num2=128):\n",
    "        \n",
    "        super(SPIB, self).__init__()\n",
    "        if encoder_type == 'Nonlinear':\n",
    "            self.encoder_type = 'Nonlinear'\n",
    "        else:\n",
    "            self.encoder_type = 'Linear'\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.neuron_num1 = neuron_num1\n",
    "        self.neuron_num2 = neuron_num2\n",
    "        \n",
    "        self.data_shape = data_shape\n",
    "        \n",
    "        self.UpdateLabel = UpdateLabel\n",
    "        \n",
    "        self.eps = 1e-10\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "\n",
    "        # representative-inputs\n",
    "        self.representative_dim = output_dim\n",
    "\n",
    "        # torch buffer, these variables will not be trained\n",
    "        self.representative_inputs = torch.eye(self.output_dim, np.prod(self.data_shape), device=device, requires_grad=False)\n",
    "        \n",
    "        # create an idle input for calling representative-weights\n",
    "        # torch buffer, these variables will not be trained\n",
    "        self.idle_input = torch.eye(self.output_dim, self.output_dim, device=device, requires_grad=False)\n",
    "\n",
    "        # representative weights\n",
    "        self.representative_weights = nn.Sequential(\n",
    "            nn.Linear(self.output_dim, 1, bias=False),\n",
    "            nn.Softmax(dim=0))\n",
    "        \n",
    "        self.encoder = self._encoder_init()\n",
    "\n",
    "        if self.encoder_type == 'Nonlinear': \n",
    "            self.encoder_mean = nn.Linear(self.neuron_num1, self.z_dim)\n",
    "        else:\n",
    "            self.encoder_mean = nn.Linear(np.prod(self.data_shape), self.z_dim)\n",
    "        \n",
    "        # Note: encoder_type = 'Linear' only means that z_mean is a linear combination of the input OPs, \n",
    "        # the log_var is always obtained through a nonlinear NN\n",
    "\n",
    "        # enforce log_var in the range of [-10, 0]\n",
    "        self.encoder_logvar = nn.Sequential(\n",
    "            nn.Linear(self.neuron_num1, self.z_dim),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.decoder = self._decoder_init()\n",
    "        \n",
    "    def _encoder_init(self):\n",
    "        \n",
    "        modules = [nn.Linear(np.prod(self.data_shape), self.neuron_num1)]\n",
    "        modules += [nn.ReLU()]\n",
    "        for _ in range(1):\n",
    "            modules += [nn.Linear(self.neuron_num1, self.neuron_num1)]\n",
    "            modules += [nn.ReLU()]\n",
    "        \n",
    "        return nn.Sequential(*modules)\n",
    "    \n",
    "    def _decoder_init(self):\n",
    "        # cross-entropy MLP decoder\n",
    "        # output the probability of future state\n",
    "        modules = [nn.Linear(self.z_dim, self.neuron_num2)]\n",
    "        modules += [nn.ReLU()]\n",
    "        for _ in range(1):\n",
    "            modules += [nn.Linear(self.neuron_num2, self.neuron_num2)]\n",
    "            modules += [nn.ReLU()]\n",
    "        \n",
    "        modules += [nn.Linear(self.neuron_num2, self.output_dim)]\n",
    "        modules += [nn.LogSoftmax(dim=1)]\n",
    "        \n",
    "        return nn.Sequential(*modules)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    \n",
    "    def encode(self, inputs):\n",
    "        enc = self.encoder(inputs)\n",
    "        \n",
    "        if self.encoder_type == 'Nonlinear': \n",
    "            z_mean = self.encoder_mean(enc)\n",
    "        else:\n",
    "            z_mean = self.encoder_mean(inputs)\n",
    "\n",
    "        # Note: encoder_type = 'Linear' only means that z_mean is a linear combination of the input OPs, \n",
    "        # the log_var is always obtained through a nonlinear NN\n",
    "        \n",
    "        # enforce log_var in the range of [-10, 0]\n",
    "        z_logvar = -10*self.encoder_logvar(enc)\n",
    "        \n",
    "        return z_mean, z_logvar\n",
    "    \n",
    "    def forward(self, data):\n",
    "        inputs = torch.flatten(data, start_dim=1)\n",
    "        \n",
    "        z_mean, z_logvar = self.encode(inputs)\n",
    "        \n",
    "        z_sample = self.reparameterize(z_mean, z_logvar)\n",
    "        \n",
    "        outputs = self.decoder(z_sample)\n",
    "        \n",
    "        return outputs, z_sample, z_mean, z_logvar\n",
    "    \n",
    "    def log_p (self, z, sum_up=True):\n",
    "        # get representative_z - representative_dim * z_dim\n",
    "        representative_z_mean, representative_z_logvar = self.get_representative_z()\n",
    "        # get representative weights - representative_dim * 1\n",
    "        w = self.representative_weights(self.idle_input)\n",
    "        # w = 0.5*torch.ones((2,1)).to(self.device)\n",
    "        \n",
    "        # expand z - batch_size * z_dim\n",
    "        z_expand = z.unsqueeze(1)\n",
    "        \n",
    "        representative_mean = representative_z_mean.unsqueeze(0)\n",
    "        representative_logvar = representative_z_logvar.unsqueeze(0)\n",
    "        \n",
    "        # representative log_q\n",
    "        representative_log_q = -0.5 * torch.sum(representative_logvar + torch.pow(z_expand-representative_mean, 2)\n",
    "                                        / torch.exp(representative_logvar), dim=2 )\n",
    "        \n",
    "        if sum_up:\n",
    "            log_p = torch.sum(torch.log(torch.exp(representative_log_q)@w + self.eps), dim=1)\n",
    "        else:\n",
    "            log_p = torch.log(torch.exp(representative_log_q)*w.T + self.eps)  \n",
    "            \n",
    "        return log_p\n",
    "        \n",
    "    # the prior\n",
    "    def get_representative_z(self):\n",
    "        # calculate representative_means\n",
    "        # with torch.no_grad():\n",
    "        X = self.representative_inputs\n",
    "\n",
    "        # calculate representative_z\n",
    "        representative_z_mean, representative_z_logvar = self.encode(X)  # C x M\n",
    "\n",
    "        return representative_z_mean, representative_z_logvar\n",
    "\n",
    "    def reset_representative(self, representative_inputs):\n",
    "        \n",
    "        # reset the nuber of representative inputs   \n",
    "        self.representative_dim = representative_inputs.shape[0]        \n",
    "        \n",
    "        # reset representative weights\n",
    "        self.idle_input = torch.eye(self.representative_dim, self.representative_dim, device=self.device, requires_grad=False)\n",
    "\n",
    "        self.representative_weights = nn.Sequential(\n",
    "            nn.Linear(self.representative_dim, 1, bias=False),\n",
    "            nn.Softmax(dim=0))\n",
    "        self.representative_weights[0].weight = nn.Parameter(torch.ones([1, self.representative_dim], device=self.device))\n",
    "        \n",
    "        # reset representative inputs\n",
    "        self.representative_inputs = representative_inputs.clone().detach()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def init_representative_inputs(self, inputs, labels):\n",
    "        state_population = labels.sum(dim=0).cpu()\n",
    "        \n",
    "        # randomly pick up one sample from each initlal state as the initial guess of representative-inputs\n",
    "        representative_inputs=[]\n",
    "        \n",
    "        for i in range(state_population.shape[-1]):\n",
    "            if state_population[i]>0:\n",
    "                index = np.random.randint(0,state_population[i])\n",
    "                representative_inputs+=[inputs[labels[:,i].bool()][index].reshape(1,-1)]\n",
    "                # print(index)\n",
    "        \n",
    "        representative_inputs = torch.cat(representative_inputs, dim=0)\n",
    "\n",
    "        self.reset_representative(representative_inputs.to(self.device))\n",
    "            \n",
    "        return representative_inputs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def estimatate_representative_inputs(self, inputs, bias, batch_size):\n",
    "        prediction = []\n",
    "        mean_rep = []\n",
    "        for i in range(0, len(inputs), batch_size):\n",
    "            batch_inputs = inputs[i:i+batch_size].to(self.device)\n",
    "        \n",
    "            # pass through VAE\n",
    "            z_mean, z_logvar = self.encode(batch_inputs)        \n",
    "            log_prediction = self.decoder(z_mean)\n",
    "            \n",
    "            # label = p/Z\n",
    "            prediction += [log_prediction.exp()]\n",
    "            \n",
    "            mean_rep += [z_mean]\n",
    "        \n",
    "        prediction = torch.cat(prediction, dim=0)\n",
    "        mean_rep = torch.cat(mean_rep, dim=0)\n",
    "        \n",
    "        max_pos = prediction.argmax(1)\n",
    "        labels = F.one_hot(max_pos, num_classes=self.output_dim)\n",
    "        \n",
    "        state_population = labels.sum(dim=0)\n",
    "        \n",
    "        # save new guess of representative-inputs\n",
    "        representative_inputs=[]\n",
    "        \n",
    "        for i in range(state_population.shape[-1]):\n",
    "            if state_population[i]>0:\n",
    "                if bias == None:\n",
    "                    center_z = ((mean_rep[labels[:,i].bool()]).mean(dim=0)).reshape(1,-1)\n",
    "                else:\n",
    "                    weights = bias[labels[:,i].bool()].reshape(-1,1)\n",
    "                    center_z = ((weights*mean_rep[labels[:,i].bool()]).sum(dim=0)/weights.sum()).reshape(1,-1)\n",
    "                \n",
    "                # find the one cloest to center_z as representative-inputs\n",
    "                dist=torch.square(mean_rep-center_z).sum(dim=-1)                \n",
    "                index = torch.argmin(dist)\n",
    "                representative_inputs+=[inputs[index].reshape(1,-1)]\n",
    "                # print(index)\n",
    "        \n",
    "        representative_inputs = torch.cat(representative_inputs, dim=0)\n",
    "            \n",
    "        return representative_inputs\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def update_labels(self, inputs, batch_size):\n",
    "        if self.UpdateLabel:\n",
    "            labels = []\n",
    "            \n",
    "            for i in range(0, len(inputs), batch_size):\n",
    "                batch_inputs = inputs[i:i+batch_size].to(self.device)\n",
    "            \n",
    "                # pass through VAE\n",
    "                z_mean, z_logvar = self.encode(batch_inputs)        \n",
    "                log_prediction = self.decoder(z_mean)\n",
    "                \n",
    "                # label = p/Z\n",
    "                labels += [log_prediction.exp()]\n",
    "            \n",
    "            labels = torch.cat(labels, dim=0)\n",
    "            max_pos = labels.argmax(1)\n",
    "            labels = F.one_hot(max_pos, num_classes=self.output_dim)\n",
    "            \n",
    "            return labels\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def save_representative_parameters(self, path, index=0):\n",
    "        \n",
    "        # output representative centers\n",
    "        representative_path = path + '_representative_inputs' + str(index) + '.npy'\n",
    "        representative_weight_path = path + '_representative_weight' + str(index) + '.npy'\n",
    "        representative_z_mean_path = path + '_representative_z_mean' + str(index) + '.npy'\n",
    "        representative_z_logvar_path = path + '_representative_z_logvar' + str(index) + '.npy'\n",
    "        os.makedirs(os.path.dirname(representative_path), exist_ok=True)\n",
    "        \n",
    "        np.save(representative_path, self.representative_inputs.cpu().data.numpy())\n",
    "        np.save(representative_weight_path, self.representative_weights(self.idle_input).cpu().data.numpy())\n",
    "        \n",
    "        representative_z_mean, representative_z_logvar = self.get_representative_z()\n",
    "        np.save(representative_z_mean_path, representative_z_mean.cpu().data.numpy())\n",
    "        np.save(representative_z_logvar_path, representative_z_logvar.cpu().data.numpy())\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def save_traj_results(self, inputs, batch_size):\n",
    "        all_prediction=[] \n",
    "        all_z_sample=[] \n",
    "        all_z_mean=[] \n",
    "        \n",
    "        for i in range(0, len(inputs), batch_size):\n",
    "            \n",
    "            batch_inputs = inputs[i:i+batch_size].to(self.device)\n",
    "        \n",
    "            # pass through VAE\n",
    "            z_mean, z_logvar = self.encode(batch_inputs)\n",
    "            z_sample = self.reparameterize(z_mean, z_logvar)\n",
    "        \n",
    "            log_prediction = self.decoder(z_mean)\n",
    "            \n",
    "            all_prediction+=[log_prediction.exp().cpu()]\n",
    "            all_z_sample+=[z_sample.cpu()]\n",
    "            all_z_mean+=[z_mean.cpu()]\n",
    "            \n",
    "        all_prediction = torch.cat(all_prediction, dim=0)\n",
    "        all_z_sample = torch.cat(all_z_sample, dim=0)\n",
    "        all_z_mean = torch.cat(all_z_mean, dim=0)\n",
    "        \n",
    "        max_pos = all_prediction.argmax(1)\n",
    "        labels = F.one_hot(max_pos, num_classes=self.output_dim)\n",
    "        \n",
    "        # save the fractional population of different states\n",
    "        population = torch.sum(labels,dim=0).float()/len(inputs)\n",
    "        return all_z_mean, all_z_sample, labels, population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "removable-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPIB_zmean(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_type, z_dim, output_dim, data_shape, device, UpdateLabel= False, neuron_num1=128, \n",
    "                 neuron_num2=128):\n",
    "        \n",
    "        super(SPIB_zmean, self).__init__()\n",
    "        if encoder_type == 'Nonlinear':\n",
    "            self.encoder_type = 'Nonlinear'\n",
    "        else:\n",
    "            self.encoder_type = 'Linear'\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.neuron_num1 = neuron_num1\n",
    "        self.neuron_num2 = neuron_num2\n",
    "        \n",
    "        self.data_shape = data_shape\n",
    "        \n",
    "        self.UpdateLabel = UpdateLabel\n",
    "        \n",
    "        self.eps = 1e-10\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "        self.encoder = self._encoder_init()\n",
    "\n",
    "        if self.encoder_type == 'Nonlinear': \n",
    "            self.encoder_mean = nn.Linear(self.neuron_num1, self.z_dim)\n",
    "        else:\n",
    "            self.encoder_mean = nn.Linear(np.prod(self.data_shape), self.z_dim)\n",
    "\n",
    "                \n",
    "    def _encoder_init(self):\n",
    "        \n",
    "        modules = [nn.Linear(np.prod(self.data_shape), self.neuron_num1)]\n",
    "        modules += [nn.ReLU()]\n",
    "        for _ in range(1):\n",
    "            modules += [nn.Linear(self.neuron_num1, self.neuron_num1)]\n",
    "            modules += [nn.ReLU()]\n",
    "        \n",
    "        return nn.Sequential(*modules)\n",
    "    \n",
    "\n",
    "    \n",
    "    def encode(self, inputs):\n",
    "        enc = self.encoder(inputs)\n",
    "        \n",
    "        if self.encoder_type == 'Nonlinear': \n",
    "            z_mean = self.encoder_mean(enc)\n",
    "        else:\n",
    "            z_mean = self.encoder_mean(inputs)\n",
    "        \n",
    "        return z_mean\n",
    "    \n",
    "    def forward(self, data):\n",
    "        inputs = torch.flatten(data, start_dim=1)\n",
    "        \n",
    "        z_mean = self.encode(inputs)\n",
    "        \n",
    "        return z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "false-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "default_device = torch.device(\"cpu\")\n",
    "\n",
    "t0 = 0\n",
    "RC_dim = 2\n",
    "encoder_type = 'Nonlinear'\n",
    "neuron_num1 = 32\n",
    "neuron_num2 = 32\n",
    "batch_size = 2000\n",
    "threshold = 0.05\n",
    "patience = 2\n",
    "refinements = 15\n",
    "log_interval = 10000\n",
    "lr_scheduler_step_size = 1\n",
    "lr_scheduler_gamma = 1\n",
    "learning_rate = 0.001\n",
    "beta = 0.0001\n",
    "\n",
    "#dcom = np.loadtxt('dxy_all.dat')\n",
    "#initial_label_np = np.loadtxt('label_all.dat')\n",
    "\n",
    "#traj_labels = torch.from_numpy(initial_label_np).float().to(device)\n",
    "\n",
    "traj_data_np = np.loadtxt('data_all.dat')\n",
    "traj_data = torch.from_numpy(traj_data_np).float().to(device)\n",
    "\n",
    "initial_label_dt = np.loadtxt('label_all2.dat')\n",
    "traj_labels_dt = torch.from_numpy(initial_label_dt).float().to(device)\n",
    "\n",
    "output_dim = initial_label_dt.shape[1]\n",
    "\n",
    "past_traj_data = np.loadtxt('past_data_all2.dat')\n",
    "past_traj_data = torch.from_numpy(past_traj_data).float().to(device)\n",
    "\n",
    "future_traj_data = np.loadtxt('future_data_all2.dat')\n",
    "future_traj_data = torch.from_numpy(future_traj_data).float().to(device)\n",
    "\n",
    "traj_weights = None\n",
    "\n",
    "seed = 0\n",
    "UpdateLabel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "committed-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPIB(\n",
       "  (representative_weights): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=1, bias=False)\n",
       "    (1): Softmax(dim=0)\n",
       "  )\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (encoder_mean): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (encoder_logvar): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=20, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape, train_past_data, train_future_data, train_data_labels, train_data_weights, \\\n",
    "        test_past_data, test_future_data, test_data_labels, test_data_weights = \\\n",
    "            data_init(traj_labels_dt, past_traj_data, future_traj_data, traj_weights)\n",
    "\n",
    "IB = SPIB(encoder_type, RC_dim, output_dim, data_shape, device, \\\n",
    "                   UpdateLabel, neuron_num1, neuron_num2)\n",
    "IB.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "breathing-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "State population change=0.840517\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "State population change=0.000000\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "State population change=0.000000\n",
      "Epoch: 3\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.2399, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7372, 0.0000, 0.0000, 0.0000,\n",
      "        0.0229, 0.0000])\n",
      "State population change=0.356509\n",
      "Epoch: 4\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.2593, 0.0026, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5614, 0.0000, 0.0000, 0.0000,\n",
      "        0.1767, 0.0000])\n",
      "State population change=0.234381\n",
      "Epoch: 5\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1714, 0.0812, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4595, 0.0000, 0.0000, 0.0000,\n",
      "        0.2878, 0.0000])\n",
      "State population change=0.191406\n",
      "Epoch: 6\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1443, 0.0983, 0.0000, 0.0000, 0.0000, 0.0897, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3698, 0.0000, 0.0000, 0.0000,\n",
      "        0.2978, 0.0000])\n",
      "State population change=0.131286\n",
      "Epoch: 7\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1412, 0.1150, 0.0000, 0.0000, 0.0000, 0.1277, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "        0.2985, 0.0000])\n",
      "State population change=0.066639\n",
      "Epoch: 8\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1353, 0.1007, 0.0000, 0.0000, 0.0000, 0.1508, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0065, 0.3671, 0.0000, 0.0000, 0.0000,\n",
      "        0.2395, 0.0000])\n",
      "State population change=0.082044\n",
      "Epoch: 9\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1347, 0.1135, 0.0000, 0.0000, 0.0000, 0.1673, 0.0020,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0088, 0.3321, 0.0000, 0.0000, 0.0000,\n",
      "        0.2414, 0.0000])\n",
      "State population change=0.040848\n",
      "Epoch: 10\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1338, 0.1261, 0.0000, 0.0000, 0.0000, 0.1790, 0.0105,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0103, 0.3148, 0.0000, 0.0000, 0.0000,\n",
      "        0.2255, 0.0000])\n",
      "State population change=0.030311\n",
      "Epoch: 11\n",
      "\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.3427e-01, 1.3366e-01, 0.0000e+00, 0.0000e+00,\n",
      "        9.2608e-05, 2.0369e-01, 2.2612e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.2193e-02, 2.9033e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.0315e-01, 0.0000e+00])\n",
      "State population change=0.043825\n",
      "Update 1\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1322, 0.1328, 0.0000, 0.0000, 0.0000, 0.2132, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3249, 0.0000, 0.0000, 0.0000,\n",
      "        0.1969, 0.0000])\n",
      "State population change=0.044591\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1324, 0.1377, 0.0000, 0.0000, 0.0000, 0.2191, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.0000, 0.0000, 0.0000,\n",
      "        0.1983, 0.0000])\n",
      "State population change=0.014637\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1322, 0.1373, 0.0000, 0.0000, 0.0000, 0.2188, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3139, 0.0000, 0.0000, 0.0000,\n",
      "        0.1979, 0.0000])\n",
      "State population change=0.001547\n",
      "Update 2\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "Iteration 500:\tTime 3.180169 s\n",
      "Loss (train) 0.463545\tKL loss (train): 27.811495\n",
      "Reconstruction loss (train) 0.460763\t Spatial loss 0.006640\n",
      "Loss (test) 0.445406\tKL loss (test): 27.900402\n",
      "Reconstruction loss (test) 0.442616\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1382, 0.0000, 0.0000, 0.0000, 0.2187, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3135, 0.0000, 0.0000, 0.0000,\n",
      "        0.1977, 0.0000])\n",
      "State population change=0.001021\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1374, 0.0000, 0.0000, 0.0000, 0.2160, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3175, 0.0000, 0.0000, 0.0000,\n",
      "        0.1971, 0.0000])\n",
      "State population change=0.004913\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1372, 0.0000, 0.0000, 0.0000, 0.2150, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3184, 0.0000, 0.0000, 0.0000,\n",
      "        0.1975, 0.0000])\n",
      "State population change=0.001437\n",
      "Update 3\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1320, 0.1376, 0.0000, 0.0000, 0.0000, 0.2146, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "        0.1981, 0.0000])\n",
      "State population change=0.001153\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1369, 0.0000, 0.0000, 0.0000, 0.2122, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3203, 0.0000, 0.0000, 0.0000,\n",
      "        0.1987, 0.0000])\n",
      "State population change=0.003688\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1369, 0.0000, 0.0000, 0.0000, 0.2120, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3205, 0.0000, 0.0000, 0.0000,\n",
      "        0.1988, 0.0000])\n",
      "State population change=0.000219\n",
      "Update 4\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1367, 0.0000, 0.0000, 0.0000, 0.2119, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3196, 0.0000, 0.0000, 0.0000,\n",
      "        0.1999, 0.0000])\n",
      "State population change=0.001453\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1359, 0.0000, 0.0000, 0.0000, 0.2089, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3237, 0.0000, 0.0000, 0.0000,\n",
      "        0.1997, 0.0000])\n",
      "State population change=0.005154\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1369, 0.0000, 0.0000, 0.0000, 0.2116, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3198, 0.0000, 0.0000, 0.0000,\n",
      "        0.1999, 0.0000])\n",
      "State population change=0.004909\n",
      "Update 5\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1369, 0.0000, 0.0000, 0.0000, 0.2197, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3107, 0.0000, 0.0000, 0.0000,\n",
      "        0.2008, 0.0000])\n",
      "State population change=0.012159\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1361, 0.0000, 0.0000, 0.0000, 0.2100, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3213, 0.0000, 0.0000, 0.0000,\n",
      "        0.2007, 0.0000])\n",
      "State population change=0.014386\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1362, 0.0000, 0.0000, 0.0000, 0.2098, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3214, 0.0000, 0.0000, 0.0000,\n",
      "        0.2007, 0.0000])\n",
      "State population change=0.000200\n",
      "Update 6\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1373, 0.0000, 0.0000, 0.0000, 0.2132, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3161, 0.0000, 0.0000, 0.0000,\n",
      "        0.2015, 0.0000])\n",
      "State population change=0.006381\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1352, 0.0000, 0.0000, 0.0000, 0.2109, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3208, 0.0000, 0.0000, 0.0000,\n",
      "        0.2012, 0.0000])\n",
      "State population change=0.005593\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1349, 0.0000, 0.0000, 0.0000, 0.2085, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3236, 0.0000, 0.0000, 0.0000,\n",
      "        0.2011, 0.0000])\n",
      "State population change=0.003759\n",
      "Update 7\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "Iteration 1000:\tTime 5.799550 s\n",
      "Loss (train) 0.130712\tKL loss (train): 23.369907\n",
      "Reconstruction loss (train) 0.128375\t Spatial loss 0.002413\n",
      "Loss (test) 0.157865\tKL loss (test): 23.226089\n",
      "Reconstruction loss (test) 0.155542\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1345, 0.0000, 0.0000, 0.0000, 0.2137, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3186, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.007230\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1351, 0.0000, 0.0000, 0.0000, 0.2103, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3214, 0.0000, 0.0000, 0.0000,\n",
      "        0.2014, 0.0000])\n",
      "State population change=0.004445\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1334, 0.0000, 0.0000, 0.0000, 0.2081, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3254, 0.0000, 0.0000, 0.0000,\n",
      "        0.2012, 0.0000])\n",
      "State population change=0.004820\n",
      "Update 8\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1350, 0.0000, 0.0000, 0.0000, 0.2086, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3230, 0.0000, 0.0000, 0.0000,\n",
      "        0.2015, 0.0000])\n",
      "State population change=0.002919\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1332, 0.0000, 0.0000, 0.0000, 0.2085, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3250, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.002694\n",
      "Epoch: 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.1319, 0.1331, 0.0000, 0.0000, 0.0000, 0.2072, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3266, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.002062\n",
      "Update 9\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1338, 0.0000, 0.0000, 0.0000, 0.2124, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3204, 0.0000, 0.0000, 0.0000,\n",
      "        0.2015, 0.0000])\n",
      "State population change=0.008080\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1331, 0.0000, 0.0000, 0.0000, 0.2091, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3246, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.005381\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1331, 0.0000, 0.0000, 0.0000, 0.2077, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3260, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.001976\n",
      "Update 10\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1333, 0.0000, 0.0000, 0.0000, 0.2080, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3254, 0.0000, 0.0000, 0.0000,\n",
      "        0.2014, 0.0000])\n",
      "State population change=0.000699\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1328, 0.0000, 0.0000, 0.0000, 0.2072, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3269, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.001793\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1331, 0.0000, 0.0000, 0.0000, 0.2077, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3260, 0.0000, 0.0000, 0.0000,\n",
      "        0.2014, 0.0000])\n",
      "State population change=0.001102\n",
      "Update 11\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1330, 0.0000, 0.0000, 0.0000, 0.2087, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3250, 0.0000, 0.0000, 0.0000,\n",
      "        0.2015, 0.0000])\n",
      "State population change=0.001411\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1325, 0.0000, 0.0000, 0.0000, 0.2059, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3286, 0.0000, 0.0000, 0.0000,\n",
      "        0.2012, 0.0000])\n",
      "State population change=0.004549\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1328, 0.0000, 0.0000, 0.0000, 0.2069, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3272, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.001739\n",
      "Update 12\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "Iteration 1500:\tTime 8.327419 s\n",
      "Loss (train) 0.031687\tKL loss (train): 20.308260\n",
      "Reconstruction loss (train) 0.029656\t Spatial loss 0.002021\n",
      "Loss (test) 0.032680\tKL loss (test): 20.278215\n",
      "Reconstruction loss (test) 0.030652\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1327, 0.0000, 0.0000, 0.0000, 0.2057, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3285, 0.0000, 0.0000, 0.0000,\n",
      "        0.2012, 0.0000])\n",
      "State population change=0.001834\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1329, 0.0000, 0.0000, 0.0000, 0.2075, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3263, 0.0000, 0.0000, 0.0000,\n",
      "        0.2015, 0.0000])\n",
      "State population change=0.002888\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1326, 0.0000, 0.0000, 0.0000, 0.2056, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3287, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.003023\n",
      "Update 13\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1325, 0.0000, 0.0000, 0.0000, 0.2005, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3340, 0.0000, 0.0000, 0.0000,\n",
      "        0.2012, 0.0000])\n",
      "State population change=0.007382\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1325, 0.0000, 0.0000, 0.0000, 0.2066, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3277, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.008778\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1326, 0.0000, 0.0000, 0.0000, 0.2037, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3304, 0.0000, 0.0000, 0.0000,\n",
      "        0.2014, 0.0000])\n",
      "State population change=0.003956\n",
      "Update 14\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1326, 0.0000, 0.0000, 0.0000, 0.2028, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3314, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.001432\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1326, 0.0000, 0.0000, 0.0000, 0.2032, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3309, 0.0000, 0.0000, 0.0000,\n",
      "        0.2015, 0.0000])\n",
      "State population change=0.000708\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1324, 0.0000, 0.0000, 0.0000, 0.2013, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3332, 0.0000, 0.0000, 0.0000,\n",
      "        0.2012, 0.0000])\n",
      "State population change=0.002928\n",
      "Update 15\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1325, 0.0000, 0.0000, 0.0000, 0.2085, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3259, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.010162\n",
      "Epoch: 1\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1324, 0.0000, 0.0000, 0.0000, 0.2030, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3314, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.007804\n",
      "Epoch: 2\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.1319, 0.1324, 0.0000, 0.0000, 0.0000, 0.2044, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3300, 0.0000, 0.0000, 0.0000,\n",
      "        0.2013, 0.0000])\n",
      "State population change=0.002074\n",
      "Total training time: 10.488907\n"
     ]
    }
   ],
   "source": [
    "IB.init_representative_inputs(train_past_data, train_data_labels)\n",
    "train_result = train(IB, beta, train_past_data, train_future_data, \\\n",
    "                                       train_data_labels, train_data_weights, test_past_data, test_future_data, \\\n",
    "                                           test_data_labels, test_data_weights, learning_rate, lr_scheduler_step_size, lr_scheduler_gamma,\\\n",
    "                                               batch_size, threshold, patience, refinements, \\\n",
    "                                                   log_interval, device, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hollywood-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 0\n",
      "Loss (train) 0.035763\tKL loss (train): 18.591139\n",
      "Reconstruction loss (train) 0.017172\n",
      "Loss (test) 0.038869\tKL loss (train): 18.697092\n",
      "Reconstruction loss (test) 0.020172\n"
     ]
    }
   ],
   "source": [
    "output_final_result(IB, device, train_past_data, train_future_data, train_data_labels, train_data_weights, \\\n",
    "                                      test_past_data, test_future_data, test_data_labels, test_data_weights, batch_size, \\\n",
    "                                      beta, learning_rate, seed)\n",
    "final_zmean, final_zsample,final_labels, final_population = IB.save_traj_results(traj_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sweet-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "np.savetxt(\"final_zmean_spib.dat\", final_zmean.detach().numpy(),fmt='%7.6f')\n",
    "np.savetxt(\"final_labels_spib.dat\", final_labels.detach().numpy(),fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rising-midnight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CV2')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data= final_zmean.detach().numpy()\n",
    "labels=final_labels.detach().numpy()\n",
    "\n",
    "hist=plt.hist2d(data[:,0],data[:,1],bins=100)\n",
    "\n",
    "state_num=labels.shape[1]\n",
    "state_labels=np.arange(state_num)\n",
    "\n",
    "hist_state=np.zeros([state_num]+list(hist[0].shape))\n",
    "\n",
    "for i in range(state_num):\n",
    "    hist_state[i]=plt.hist2d(data[:,0],data[:,1],bins=[hist[1],hist[2]],weights=labels[:,i])[0]\n",
    "    \n",
    "label_map50=np.argmax(hist_state,axis=0).astype(float)\n",
    "label_map50[hist[0]==0]=np.nan\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "\n",
    "fmt = matplotlib.ticker.FuncFormatter(lambda x, pos: state_labels[x])\n",
    "tickz = np.arange(0,len(state_labels))\n",
    "\n",
    "cMap = c.ListedColormap(plt.cm.tab20.colors[0:20])\n",
    "im=ax.pcolormesh(hist[1], hist[2], label_map50.T, cmap=cMap, vmin=-0.5, vmax=len(state_labels)-0.5)\n",
    "cb1 = fig.colorbar(im,ax=ax,format=fmt, ticks=tickz)\n",
    "\n",
    "\n",
    "plt.xlabel(\"CV1\")\n",
    "plt.ylabel(\"CV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "instructional-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_name = \"model\"\n",
    "tr_folder=model_name+\"/\"\n",
    "!mkdir -p \"{tr_folder}\"\n",
    "\n",
    "torch.save(IB.state_dict(), tr_folder+model_name+'_state_dict.pt')\n",
    "\n",
    "fake_data = traj_data[0].unsqueeze(0)\n",
    "IB2 = SPIB_zmean(encoder_type, RC_dim, output_dim, data_shape, device, \\\n",
    "                   UpdateLabel, neuron_num1, neuron_num2)\n",
    "IB2.to(device)\n",
    "params = IB.named_parameters()\n",
    "params2 = IB2.named_parameters()\n",
    "dict_params2 = dict(params2)\n",
    "for name, param in params:\n",
    "    if name in dict_params2:\n",
    "        dict_params2[name].data.copy_(param.data)\n",
    "        \n",
    "# save model\n",
    "mod2 = torch.jit.trace(IB2, fake_data)\n",
    "mod2.save(tr_folder+model_name+\"_zmean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "wired-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPIB(\n",
      "  (representative_weights): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=1, bias=False)\n",
      "    (1): Softmax(dim=0)\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=36, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (encoder_mean): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (encoder_logvar): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=2, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=20, bias=True)\n",
      "    (5): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(IB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
